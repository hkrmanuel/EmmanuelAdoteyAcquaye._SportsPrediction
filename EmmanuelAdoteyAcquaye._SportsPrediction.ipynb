{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff208dba-1abc-4b2d-98ab-989ec54d6232",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "\n",
    "\n",
    "This project involves building a machine learning model to predict FIFA player ratings based on hsitorical player data. The process includes data preparation, feature selection, model training, evaluation and deployment. By levaraging cross-validatio abd optimization techniques, the model aims to accurately predict player ratings even on unseen data from a different season. The final step involves deploying the model on a web platform to make it accessible and user-friendly, demonstrating its functionality via video tutorial.\n",
    "\n",
    "This structured approach ensures that each phase of the project from data handling to deployment is handled systematically to achieve accurate predictions and a functional end product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b76ef6d-8810-4579-a5fa-27d77e413496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ddbdbe-9eff-4f6c-8a47-e988a3b5c22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkrma\\AppData\\Local\\Temp\\ipykernel_22448\\161522061.py:1: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  players_22 = pd.read_csv('players_22.csv')\n",
      "C:\\Users\\hkrma\\AppData\\Local\\Temp\\ipykernel_22448\\161522061.py:2: DtypeWarning: Columns (108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  male_player =pd.read_csv('male_players (legacy).csv')\n"
     ]
    }
   ],
   "source": [
    "players_22 = pd.read_csv('players_22.csv')\n",
    "male_player =pd.read_csv('male_players (legacy).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e004657-c631-4ad3-af7a-99cfcc9fe1c8",
   "metadata": {},
   "source": [
    "## Import Explanation\n",
    "1. pandas('import pandas as pd'):\n",
    "   Pandas is a powerful data analysis and manipulation library for Python. it provides data structures like DataFrame and Series,       which are essential for working with structured data.\n",
    "   \n",
    "2. numpy('import numpy as np'):\n",
    "   Numpy is a fundamental package for numerical computing in Python. It provides support for large, multi-dimensional functions to      operate on these arrays.\n",
    "\n",
    "3. joblib ('import joblub'):\n",
    "   Joblib is alibrary for saving and loading Python objects(serialized objects). It is particularly useful for saving scikit-learn      modelx after training for later use.\n",
    "\n",
    "4. train_test_split ('from sklearn.model_selection import train_test_split'):\n",
    "   'train_test_split' is a function from scikit-learn that splits arrays or matrices into random train and test subsets. This is        useful for splitting your dataset into training and testing sets for model validation.\n",
    "\n",
    "5. StandardScaler (from sklearn.preprocessing import StandardScaler):\n",
    "   This is a class form the scikit-learn used for standardizing features by removing the mean and scaling to unit variance. It ensures that each feature in the input data has a mean of 0 and a standard deviation of 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671ab2b-a206-42b9-8e09-18bfdc2e5642",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "This is crucial because it is used to understand the structure, relationship, and distribution of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3272da44-6a1b-4da0-97da-cd59ebca8424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id                                        player_url  fifa_version  \\\n",
      "0     158023                /player/158023/lionel-messi/150002            15   \n",
      "1      20801  /player/20801/c-ronaldo-dos-santos-aveiro/150002            15   \n",
      "2       9014                  /player/9014/arjen-robben/150002            15   \n",
      "3      41236           /player/41236/zlatan-ibrahimovic/150002            15   \n",
      "4     167495                /player/167495/manuel-neuer/150002            15   \n",
      "\n",
      "   fifa_update fifa_update_date         short_name  \\\n",
      "0            2       2014-09-18           L. Messi   \n",
      "1            2       2014-09-18  Cristiano Ronaldo   \n",
      "2            2       2014-09-18          A. Robben   \n",
      "3            2       2014-09-18     Z. Ibrahimović   \n",
      "4            2       2014-09-18           M. Neuer   \n",
      "\n",
      "                             long_name player_positions  overall  potential  \\\n",
      "0       Lionel Andrés Messi Cuccittini               CF       93         95   \n",
      "1  Cristiano Ronaldo dos Santos Aveiro           LW, LM       92         92   \n",
      "2                         Arjen Robben       RM, LM, RW       90         90   \n",
      "3                   Zlatan Ibrahimović               ST       90         90   \n",
      "4                   Manuel Peter Neuer               GK       90         90   \n",
      "\n",
      "   ...   cdm   rdm   rwb    lb   lcb    cb   rcb    rb    gk  \\\n",
      "0  ...  62+3  62+3  62+3  54+3  45+3  45+3  45+3  54+3  15+3   \n",
      "1  ...  63+3  63+3  63+3  57+3  52+3  52+3  52+3  57+3  16+3   \n",
      "2  ...  64+3  64+3  64+3  55+3  46+3  46+3  46+3  55+3  14+3   \n",
      "3  ...  65+3  65+3  61+3  56+3  55+3  55+3  55+3  56+3  17+3   \n",
      "4  ...  40+3  40+3  36+3  36+3  38+3  38+3  38+3  36+3  87+3   \n",
      "\n",
      "                                     player_face_url  \n",
      "0  https://cdn.sofifa.net/players/158/023/15_120.png  \n",
      "1  https://cdn.sofifa.net/players/020/801/15_120.png  \n",
      "2  https://cdn.sofifa.net/players/009/014/15_120.png  \n",
      "3  https://cdn.sofifa.net/players/041/236/15_120.png  \n",
      "4  https://cdn.sofifa.net/players/167/495/15_120.png  \n",
      "\n",
      "[5 rows x 110 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161583 entries, 0 to 161582\n",
      "Columns: 110 entries, player_id to player_face_url\n",
      "dtypes: float64(18), int64(45), object(47)\n",
      "memory usage: 135.6+ MB\n",
      "None\n",
      "           player_id   fifa_version  fifa_update        overall  \\\n",
      "count  161583.000000  161583.000000     161583.0  161583.000000   \n",
      "mean   214484.722353      19.125514          2.0      65.699071   \n",
      "std     34928.608856       2.559318          0.0       7.040855   \n",
      "min         2.000000      15.000000          2.0      40.000000   \n",
      "25%    199159.000000      17.000000          2.0      61.000000   \n",
      "50%    220621.000000      19.000000          2.0      66.000000   \n",
      "75%    236958.000000      21.000000          2.0      70.000000   \n",
      "max    271817.000000      23.000000          2.0      94.000000   \n",
      "\n",
      "           potential     value_eur       wage_eur            age  \\\n",
      "count  161583.000000  1.595300e+05  159822.000000  161583.000000   \n",
      "mean       70.744008  2.326770e+06   10855.409768      25.123181   \n",
      "std         6.259121  6.005746e+06   21941.656285       4.670207   \n",
      "min        40.000000  1.000000e+03     500.000000      16.000000   \n",
      "25%        66.000000  3.250000e+05    2000.000000      21.000000   \n",
      "50%        70.000000  7.250000e+05    4000.000000      25.000000   \n",
      "75%        75.000000  1.800000e+06   10000.000000      28.000000   \n",
      "max        95.000000  1.940000e+08  575000.000000      54.000000   \n",
      "\n",
      "           height_cm      weight_kg  ...  mentality_composure  \\\n",
      "count  161583.000000  161583.000000  ...        128722.000000   \n",
      "mean      181.240205      75.235031  ...            57.816892   \n",
      "std         6.750148       7.000456  ...            12.329739   \n",
      "min       154.000000      49.000000  ...             3.000000   \n",
      "25%       176.000000      70.000000  ...            50.000000   \n",
      "50%       181.000000      75.000000  ...            59.000000   \n",
      "75%       186.000000      80.000000  ...            66.000000   \n",
      "max       208.000000     110.000000  ...            96.000000   \n",
      "\n",
      "       defending_marking_awareness  defending_standing_tackle  \\\n",
      "count                161583.000000              161583.000000   \n",
      "mean                     45.757957                  47.669996   \n",
      "std                      20.453699                  21.336404   \n",
      "min                       1.000000                   2.000000   \n",
      "25%                      26.000000                  27.000000   \n",
      "50%                      50.000000                  54.000000   \n",
      "75%                      63.000000                  66.000000   \n",
      "max                      94.000000                  94.000000   \n",
      "\n",
      "       defending_sliding_tackle  goalkeeping_diving  goalkeeping_handling  \\\n",
      "count             161583.000000        161583.00000         161583.000000   \n",
      "mean                  45.698588            16.52961             16.274918   \n",
      "std                   20.935273            17.67047             16.834294   \n",
      "min                    3.000000             1.00000              1.000000   \n",
      "25%                   25.000000             8.00000              8.000000   \n",
      "50%                   52.000000            11.00000             11.000000   \n",
      "75%                   64.000000            14.00000             14.000000   \n",
      "max                   95.000000            91.00000             92.000000   \n",
      "\n",
      "       goalkeeping_kicking  goalkeeping_positioning  goalkeeping_reflexes  \\\n",
      "count        161583.000000            161583.000000         161583.000000   \n",
      "mean             16.140374                16.288861             16.636973   \n",
      "std              16.476466                16.998697             17.980143   \n",
      "min               1.000000                 1.000000              1.000000   \n",
      "25%               8.000000                 8.000000              8.000000   \n",
      "50%              11.000000                11.000000             11.000000   \n",
      "75%              14.000000                14.000000             14.000000   \n",
      "max              95.000000                92.000000             94.000000   \n",
      "\n",
      "       goalkeeping_speed  \n",
      "count       17969.000000  \n",
      "mean           39.149090  \n",
      "std            10.503788  \n",
      "min            12.000000  \n",
      "25%            31.000000  \n",
      "50%            41.000000  \n",
      "75%            46.000000  \n",
      "max            68.000000  \n",
      "\n",
      "[8 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "print(male_player.head()) #prints out the first 5 rows\n",
    "print(male_player.info()) #provides a concise summary of the dataframe.\n",
    "print(male_player.describe()) #provides a summary statistic of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee533d-68fa-4b60-847d-b7460f382cc5",
   "metadata": {},
   "source": [
    "# 1.Demonstrate the data preparation & feature extraction process [5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941faaab-c076-4538-8693-0db1645d02ad",
   "metadata": {},
   "source": [
    "## Function Breakdownm\n",
    "@param: data - represents the entire dataset.\n",
    "        d_num - represents the subset of the dataset that contaisn only numeric feartures.\n",
    "        \n",
    "@body [Standard Scaling for Numerical Data]:\n",
    "\n",
    "        Standard Scaler() - standardizes features by removing the mean and scaling to unit variance.\n",
    "\n",
    "        \n",
    "        scaler.fit_transform(d_num) - This fits the scaler to the numerical data (d_num) and transforms it. \n",
    "\n",
    "        \n",
    "        dataset_num_scaled_df - converts the scaled numpy array back into a pandas Dataframe.\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc34daf-3095-486a-a462-6546ceaa4cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The preprocessing function performs standard scaling on numerical data and saves the scaler object for future use(i.e in the deployment stage)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(d_num):\n",
    "    # Standard scaling for numerical data\n",
    "    scaler = StandardScaler()\n",
    "    d_num_scaled = scaler.fit_transform(d_num)\n",
    "    \n",
    "    # Convert the scaled numerical data back to a DataFrame\n",
    "    dataset_num_scaled_df = pd.DataFrame(d_num_scaled, columns=d_num.columns)\n",
    "    \n",
    "\n",
    "    return dataset_num_scaled_df\n",
    "    \n",
    "'''The preprocessing function performs standard scaling on numerical data '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91057046-c9aa-40c7-8500-741ea07a0a46",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "The data cleaning function performs initial data cleaning tasks on the given dataset. It drops all columsn that have more than 20 % missing valeus, separates numerical and categorial columns and fills missing vlaues in numericla columns with their means. The preprocessing function is then called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd82a16b-0039-46b5-9144-19ed0e964943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(dataset):\n",
    "    # Drop columns with more than 20% missing values\n",
    "    columns_to_drop = []\n",
    "    for col in dataset.columns:\n",
    "        missing = dataset[col].isnull().sum()\n",
    "        if (missing / len(dataset[col])) * 100 > 20:\n",
    "            columns_to_drop.append(col)\n",
    "    dataset.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    # Separate numerical and categorical columns\n",
    "    dataset_num = dataset.select_dtypes(include=[np.number])\n",
    "    dataset_cat = dataset.select_dtypes(include=['object'])\n",
    "\n",
    "    '''Looking at the function in question, the categorial data is separated from the datat set and dropped. This is because most of the categorial data in the \n",
    "    dataset have little to no correlation to the Y values \"overall\". Also, encoding these values will lead to the creation of multiple columns leading to longer runtimes and lower e\n",
    "    efficiency of the model. Therefore for this model, all categorial columns where dropped, leaving the prediction of the overall to be based on numerical data.'''\n",
    "    \n",
    "    # Fill missing values in numerical data with mean\n",
    "    dataset_num.fillna(dataset_num.mean(), inplace=True)\n",
    "    \n",
    "    return dataset_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc60f51-b225-4ceb-9231-e9cfc6c01123",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_22 = data_cleaning(players_22)# cleaned test dataset\n",
    "male_player_clean = data_cleaning(male_player) # cleaned train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d570635-c53b-46bf-a49d-ce82258eaddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>fifa_version</th>\n",
       "      <th>fifa_update</th>\n",
       "      <th>overall</th>\n",
       "      <th>potential</th>\n",
       "      <th>value_eur</th>\n",
       "      <th>wage_eur</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>...</th>\n",
       "      <th>mentality_vision</th>\n",
       "      <th>mentality_penalties</th>\n",
       "      <th>defending_marking_awareness</th>\n",
       "      <th>defending_standing_tackle</th>\n",
       "      <th>defending_sliding_tackle</th>\n",
       "      <th>goalkeeping_diving</th>\n",
       "      <th>goalkeeping_handling</th>\n",
       "      <th>goalkeeping_kicking</th>\n",
       "      <th>goalkeeping_positioning</th>\n",
       "      <th>goalkeeping_reflexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158023</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>100500000.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>27</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>79000000.0</td>\n",
       "      <td>375000.0</td>\n",
       "      <td>29</td>\n",
       "      <td>185</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>85</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9014</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>54500000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41236</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>52500000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>32</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167495</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>28</td>\n",
       "      <td>193</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161578</th>\n",
       "      <td>269011</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>18</td>\n",
       "      <td>180</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161579</th>\n",
       "      <td>269019</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161580</th>\n",
       "      <td>271093</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161581</th>\n",
       "      <td>271555</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161582</th>\n",
       "      <td>271608</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161583 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        player_id  fifa_version  fifa_update  overall  potential    value_eur  \\\n",
       "0          158023            15            2       93         95  100500000.0   \n",
       "1           20801            15            2       92         92   79000000.0   \n",
       "2            9014            15            2       90         90   54500000.0   \n",
       "3           41236            15            2       90         90   52500000.0   \n",
       "4          167495            15            2       90         90   63500000.0   \n",
       "...           ...           ...          ...      ...        ...          ...   \n",
       "161578     269011            23            2       46         61     110000.0   \n",
       "161579     269019            23            2       46         58     110000.0   \n",
       "161580     271093            23            2       46         58     110000.0   \n",
       "161581     271555            23            2       46         70     150000.0   \n",
       "161582     271608            23            2       46         63     110000.0   \n",
       "\n",
       "        wage_eur  age  height_cm  weight_kg  ...  mentality_vision  \\\n",
       "0       550000.0   27        169         67  ...                90   \n",
       "1       375000.0   29        185         80  ...                81   \n",
       "2       275000.0   30        180         80  ...                84   \n",
       "3       275000.0   32        195         95  ...                83   \n",
       "4       300000.0   28        193         92  ...                20   \n",
       "...          ...  ...        ...        ...  ...               ...   \n",
       "161578     700.0   18        180         73  ...                42   \n",
       "161579     750.0   19        188         83  ...                31   \n",
       "161580     500.0   19        181         73  ...                40   \n",
       "161581     500.0   17        175         68  ...                44   \n",
       "161582     500.0   17        180         70  ...                20   \n",
       "\n",
       "        mentality_penalties  defending_marking_awareness  \\\n",
       "0                        76                           25   \n",
       "1                        85                           22   \n",
       "2                        80                           29   \n",
       "3                        91                           25   \n",
       "4                        37                           25   \n",
       "...                     ...                          ...   \n",
       "161578                   54                           23   \n",
       "161579                   31                           50   \n",
       "161580                   37                           36   \n",
       "161581                   63                           19   \n",
       "161582                   25                           50   \n",
       "\n",
       "        defending_standing_tackle  defending_sliding_tackle  \\\n",
       "0                              21                        20   \n",
       "1                              31                        23   \n",
       "2                              26                        26   \n",
       "3                              41                        27   \n",
       "4                              25                        25   \n",
       "...                           ...                       ...   \n",
       "161578                         21                        25   \n",
       "161579                         51                        45   \n",
       "161580                         45                        50   \n",
       "161581                         17                        14   \n",
       "161582                         45                        42   \n",
       "\n",
       "        goalkeeping_diving  goalkeeping_handling  goalkeeping_kicking  \\\n",
       "0                        6                    11                   15   \n",
       "1                        7                    11                   15   \n",
       "2                       10                     8                   11   \n",
       "3                       13                    15                   10   \n",
       "4                       87                    85                   92   \n",
       "...                    ...                   ...                  ...   \n",
       "161578                   9                    13                   13   \n",
       "161579                   6                    14                    8   \n",
       "161580                   8                     9                    7   \n",
       "161581                  13                    12                   14   \n",
       "161582                  13                     7                    6   \n",
       "\n",
       "        goalkeeping_positioning  goalkeeping_reflexes  \n",
       "0                            14                     8  \n",
       "1                            14                    11  \n",
       "2                             5                    15  \n",
       "3                             9                    12  \n",
       "4                            90                    86  \n",
       "...                         ...                   ...  \n",
       "161578                       12                     7  \n",
       "161579                       13                    14  \n",
       "161580                       14                     9  \n",
       "161581                        7                    13  \n",
       "161582                        6                    14  \n",
       "\n",
       "[161583 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_player_clean # display of cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41188818-ed15-4739-b29a-886f6fb4d5dc",
   "metadata": {},
   "source": [
    "## 2. Create feature subsets that show maximum correlation with the dependent variable. [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13988771-3781-45dc-82d9-e0854ac58c1f",
   "metadata": {},
   "source": [
    "## Correlation and Feature Engineering \n",
    "The function helps identify the most influential features related to the target variable, which can be useful for feature selction in the machine learning .\n",
    "\n",
    "# Function Breakdown:\n",
    "Compute Correlation Matrix: The correlation matrix shows how each pair of variables is related.\n",
    "\n",
    "\n",
    "Correlation with Target Variable: By focusing on the overall column, you can see which features are most strongly related to the target variable.\n",
    "\n",
    "\n",
    "Select High Correlation Variables: Variables with a correlation greater than 0.5 are considered to have a strong relationship with the target variable.\n",
    "\n",
    "\n",
    "Remove Target Variable: The target variable overall is excluded from the list since it is not a predictor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36b610f-0a5b-4b88-b000-aafbfefcdef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preciding variables are: ['movement_reactions', 'potential', 'passing', 'wage_eur', 'value_eur', 'dribbling']\n"
     ]
    }
   ],
   "source": [
    "def correlation(dataset):\n",
    "    corr_matrix = dataset.corr() #calculates correlation of all columns in the dataset\n",
    "    corr_with_overall = corr_matrix['overall'].abs().sort_values(ascending=False)  #extracts the correlation values of all features with teh target variable 'overall'. The absolute values of the correlations are taken to consider both positive and negative correlations.\n",
    "    preciding_variables = corr_with_overall[corr_with_overall > 0.5].index.tolist()  # selects the features that have an abs correlation greater than 0.5.\n",
    "    preciding_variables.remove('overall') # removes target variable.\n",
    "\n",
    "    \n",
    "    return preciding_variables  #return variables\n",
    "\n",
    "high_corr = correlation(male_player_clean)\n",
    "print('The preciding variables are:', high_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403c0e9-44e0-42e2-bef3-26182e3ea4b6",
   "metadata": {},
   "source": [
    "## 3.Create and train a suitable machine learning model with cross-validation that can predict a player's rating. [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0022b4-33fb-4256-b1e3-522757a411e6",
   "metadata": {},
   "source": [
    "## Import Explanation\n",
    "1. train_test_split and KFold from sklearn.model_selection:\n",
    "   'trai_test_split': splits the dataset into training and testing sets.\n",
    "   \n",
    "   'KFold': provides cross-validaipn functionalit. it splits the dataset into 'K' folds for cross-validation, whcih helps in\n",
    "    evaluationg mdoel mode robustly.\n",
    "   \n",
    "2. Metrics for Model Evaluation from sklearn.metrics:\n",
    "   Mean Absolute Error: measures the average absolute errors between predicted and actual values.\n",
    "   \n",
    "   Mean Squared Error: measures the average squared errors between predicted and actual values.\n",
    "   \n",
    "   Mean Squared Log Error: measures the mean squared logarithmic errors between predicted and actual values.\n",
    "   \n",
    "   R2 scores: measures the proportion of variance in the depemndent that is predictable from the independent variables.\n",
    "   \n",
    "3. Regression Models:\n",
    "   Linear Regression: this is a simple and widely uesed model for regression tasks\n",
    "\n",
    "   Decision Tree Regressor: implements decision tree regression. Captures non-linear relationships in the data.\n",
    "\n",
    "   XGBRegressor from 'xgboost': implements XGBoost regression. it implements gradient boosting .\n",
    "   \n",
    "6. Model Selection Tools:\n",
    "   cros_val_score from 'sklearn.model,_selection': evaluares a model using cross validation by averaging the results of the multiple\n",
    "   train-test splits.\n",
    "\n",
    "   GridSearchCV from 'sklearn.model,_selection': performs grid search over specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d375f9-16e2-4704-95e9-900378cb6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ec1037-1c57-4650-90ab-e07f57938ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = male_player_clean[high_corr]\n",
    "X = preprocessing(X)\n",
    "# Select only the highly correlated features for the input features X\n",
    "Y= male_player_clean['overall'] \n",
    "\n",
    "Xtrain,X_train_test,Ytrain,Y_train_test=train_test_split(X, Y,test_size=0.2,random_state=42)  # Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c56c7-2ea9-48fe-be94-e12a0127e5a1",
   "metadata": {},
   "source": [
    "# Linear Regression Function BreakDown\n",
    "This function trains and evaluates a linear regression model. it fits the mdoel to the training data and evaluates the predicitions on the test data using various metrics. \n",
    "\n",
    "Initialization and Fitting:\n",
    "\n",
    "lin_reg = LinearRegression(): Initializes the Linear Regression model.\n",
    "\n",
    "lin_reg.fit(X_train, Y_train): Fits the model to the training data.\n",
    "\n",
    "\n",
    "Prediction:\n",
    "\n",
    "y_pred = lin_reg.predict(X_test): Predicts the target values for the test data.\n",
    "Evaluation Metrics:\n",
    "\n",
    "mean_absolute_error(Y_test, y_pred): Computes the Mean Absolute Error between the actual and predicted values.\n",
    "\n",
    "mean_squared_error(Y_test, y_pred): Computes the Mean Squared Error.\n",
    "\n",
    "np.sqrt(mean_squared_error(Y_test, y_pred)): Computes the Root Mean Squared Error.\n",
    "\n",
    "r2_score(Y_test, y_pred): Computes the R² score, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea869bdd-1fe4-47e4-86fc-127d6e957164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearReg(X, Y, Xt, Yt):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X, Y)\n",
    "    y_pred=lin_reg.predict(Xt)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Mean Absolute Error={mean_absolute_error(y_pred, Yt)}\n",
    "    Mean Squared Error={mean_squared_error(y_pred,Yt)}\n",
    "    Root Mean Squared Error={np.sqrt(mean_squared_error(y_pred, Yt))}\n",
    "    R2 score={r2_score(y_pred, Yt)}\n",
    "    \"\"\")\n",
    "    return lin_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c53b27-0364-4559-9f2a-8d74ce116492",
   "metadata": {},
   "source": [
    "## Decision Tree Regression Function Breakdown\n",
    "This function predicts continuous numerical values based on the structure of a decision tree. \n",
    "\n",
    "Initialization and Fitting:\n",
    "\n",
    "dtree = DecisionTreeRegressor(): Initializes the Decision Tree Regressor model.\n",
    "\n",
    "dtree.fit(X, Y): Fits the model to the training data.\n",
    "\n",
    "mean_absolute_error(Yt, y_pred): Computes the Mean Absolute Error between the actual and predicted values.\n",
    "\n",
    "mean_squared_error(Yt, y_pred): Computes the Mean Squared Error.\n",
    "\n",
    "np.sqrt(mean_squared_error(Yt, y_pred)): Computes the Root Mean Squared Error.\n",
    "\n",
    "r2_score(Yt, y_pred): Computes the R² score, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c5b2b5-a83a-4c86-8f38-8064ad58ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desiciontree(X, Y, Xt, Yt):    \n",
    "    dtree = DecisionTreeRegressor()\n",
    "    dtree.fit(X,Y)\n",
    "    y_pred_tree = dtree.predict(Xt) # predicts X_train_tes\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Decision Tree regressor\n",
    "    Mean Absolute Error={mean_absolute_error(y_pred_tree, Yt)}\n",
    "    Mean Squared Error={mean_squared_error(y_pred_tree,Yt)}\n",
    "    Root Mean Squared Error={np.sqrt(mean_squared_error(y_pred_tree, Yt))}\n",
    "    R2 score={r2_score(y_pred_tree, Yt)}\n",
    "    \"\"\") \n",
    "    return dtree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57e50c-7e8c-4f2f-8fb6-07eb47b381a4",
   "metadata": {},
   "source": [
    "## Random Forest Regressor Function Breakdown\n",
    "\n",
    "This function provides a consistent way to train and evaluate a Random Forest Regressor, making it easier to compare its performance with other models such as Linear Regression and Decision Tree Regressor.\n",
    "\n",
    "Initialization and Fitting:\n",
    "\n",
    "forest_model = RandomForestRegressor(): Initializes the Random Forest Regressor model.\n",
    "\n",
    "forest_model.fit(X, Y): Fits the model to the training data.\n",
    "\n",
    "Prediction:\n",
    "\n",
    "mean_absolute_error(Y_test, y_pred): Computes the Mean Absolute Error between the actual and predicted values.\n",
    "\n",
    "mean_squared_error(Y_test, y_pred): Computes the Mean Squared Error.\n",
    "\n",
    "np.sqrt(mean_squared_error(Y_test, y_pred)): Computes the Root Mean Squared Error.\n",
    "\n",
    "r2_score(Y_test, y_pred): Computes the R² score, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a0cecdd-50fe-4603-af90-927e47de3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforestreg(X, Y, Xt, Yt):\n",
    "    forest_model=RandomForestRegressor()\n",
    "    forest_model.fit(X,Y)\n",
    "    y_pred_rand = forest_model.predict(Xt)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Random Forest Tree Regressor \n",
    "    Mean Absolute Error={mean_absolute_error(y_pred_rand, Yt)}\n",
    "    Mean Squared Error={mean_squared_error(y_pred_rand,Yt)}\n",
    "    Root Mean Squared Error={np.sqrt(mean_squared_error(y_pred_rand, Yt))}\n",
    "    R2 score={r2_score(y_pred_rand, Yt)}\n",
    "    \"\"\") \n",
    "\n",
    "    return forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ffbd44-7993-467d-8261-d759f30bc177",
   "metadata": {},
   "source": [
    "## XGBOOST Function Breakdown\n",
    "\n",
    "Initialization and Fitting:\n",
    "\n",
    "xg_model = XGBRegressor(): Initializes the XGB Regressor model.\n",
    "\n",
    "xg_model.fit(X, Y): Fits the model to the training data.\n",
    "\n",
    "Prediction:\n",
    "\n",
    "mean_absolute_error(Y_test, y_pred): Computes the Mean Absolute Error between the actual and predicted values.\n",
    "\n",
    "mean_squared_error(Y_test, y_pred): Computes the Mean Squared Error.\n",
    "\n",
    "np.sqrt(mean_squared_error(Y_test, y_pred)): Computes the Root Mean Squared Error.\n",
    "\n",
    "r2_score(Y_test, y_pred): Computes the R² score, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d3b154-eb1d-4211-ad42-8bcb9c8c7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xgboostreg(X, Y,Xt,Yt):\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.fit(X,Y)\n",
    "    y_boost = xgb_model.predict(Xt)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    XGBoost \n",
    "    Mean Absolute Error={mean_absolute_error(y_boost, Yt)}\n",
    "    Mean Squared Error={mean_squared_error(y_boost,Yt)}\n",
    "    Root Mean Squared Error={np.sqrt(mean_squared_error(y_boost, Yt))}\n",
    "    R2 score={r2_score(y_boost, Yt)}\n",
    "    \"\"\") \n",
    "\n",
    "    return xgb_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6973428-8288-4a2a-a256-7d8950b4f805",
   "metadata": {},
   "source": [
    "## Cross Eval Function\n",
    "it is designed to perform corss-valkidation on a given model, using a specidied datasaet and calculate the mean R2 score.\n",
    "\n",
    "Cross-validation is a techique used to acquire the general performance of a model by dividing the data into mulitiple folds and training and testing the mdoel on these folds. \n",
    "\n",
    "@param:\n",
    "    model - specified dataset\n",
    "    \n",
    "    X - Xtrain\n",
    "    \n",
    "    Y- Ytrain\n",
    "\n",
    "@body\n",
    "    cv - initializes the Kfold Cross Validator\n",
    "\n",
    "    cv-scores - evaluates a model using cross-validation\n",
    "\n",
    "'''prints out the r2 score of the mdoel'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8680bf56-562f-4914-b7d7-9ea8a523c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosseval(model, X, Y):\n",
    "    # Initializes K-fold cross-validator\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X, Y, cv=cv, scoring='r2')\n",
    "\n",
    "    #print mean R2 score \n",
    "    print(f'{model.__class__.__name__} CV mean R2 score: {cv_scores.mean()}')\n",
    "\n",
    "    #return mean R2 score\n",
    "    return cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399eb15e-6cd7-4c60-a9fe-c27f2e3f6fbc",
   "metadata": {},
   "source": [
    "## Hyper Tuning \n",
    "This function allows for flexible hyperparameter tuning of the Random Forest Regressor model, enhancing the overall performance and making it easier to test the model and its configuration.\n",
    "\n",
    "@ param: model - specified dataset\n",
    "\n",
    "body:\n",
    "\n",
    "cv - initializes model parameter\n",
    "param_grid-sccreates a dictionary of aparameters for tuning \n",
    "\n",
    "grid_search  - performs the serach over defined hyperparameter grid.\n",
    "\n",
    "return grid_search.best_estimator_  - Returns the model with the best combination of hyperparameters found during the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d316542-1f0d-48bb-b37e-79840d373732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(model):\n",
    "    # Define hyperparameter grid based on the model type\n",
    "    select = model\n",
    "\n",
    "    if model.__class__.__name__ == 'RandomForestRegressor':\n",
    "        # Hyperparameter tuning using GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [100],\n",
    "            'max_depth': [10, 20],\n",
    "            'min_samples_split': [5]\n",
    "        }\n",
    "    elif model.__class__.__name__ == 'XGBRegressor':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 6, 9],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.6, 0.8, 1.0]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported for hyperparameter tuning.\")\n",
    "\n",
    "        \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "    grid_search = GridSearchCV(select, param_grid, cv=cv, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(Xtrain, Ytrain)\n",
    "    \n",
    "    # return Best model\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413327a-22a3-45c1-984c-4d1490107c0a",
   "metadata": {},
   "source": [
    "## Select Model Training Function\n",
    "The 'select_model_training' function runs the various functions above sequentially to acquire an optimised model for fine tuning and testing with the test data set .\n",
    "\n",
    "It consists of  if, elif statements to select a specific model for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51573df7-82a5-4906-afdd-8eb0e1cd97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_training(Xtrain, Ytrain, X_train_test,Y_train_test):\n",
    "   \n",
    "  \n",
    "    linearReg(Xtrain, Ytrain, X_train_test,Y_train_test) #runs linear regression function \n",
    "    desiciontree(Xtrain, Ytrain, X_train_test, Y_train_test) # runs decision tree function\n",
    "    randomforestreg(Xtrain, Ytrain, X_train_test, Y_train_test) #runs random forest regression function\n",
    "    Xgboostreg(Xtrain, Ytrain, X_train_test, Y_train_test) # runs XGB regresssor function\n",
    "    \n",
    "\n",
    "    #cross evaluation\n",
    "    lin_reg_crossval = crosseval(LinearRegression(),Xtrain, Ytrain) \n",
    "    random_forest_crossval = crosseval(RandomForestRegressor(),Xtrain, Ytrain)\n",
    "    decision_crossval = crosseval(DecisionTreeRegressor(),Xtrain, Ytrain)\n",
    "    Xgboost_crossval = crosseval(XGBRegressor(),Xtrain, Ytrain)\n",
    "\n",
    "    '''The above code cross validates all the selected model  to acquire the R2 score of each model.'''\n",
    "    \n",
    "    if lin_reg_crossval > random_forest_crossval and lin_reg_crossval > decision_crossval and lin_reg_crossval > Xgboost_crossval:\n",
    "        best_model = hyperparameter_tuning(LinearRegression())\n",
    "    elif random_forest_crossval > lin_reg_crossval and random_forest_crossval > decision_crossval:\n",
    "        best_model= hyperparameter_tuning(RandomForestRegressor())\n",
    "    elif Xgboost_crossval > random_forest_crossval and Xgboost_crossval > decision_crossval and Xgboost_crossval >lin_reg_crossval:\n",
    "        best_model = hyperparameter_tuning(XGBRegressor())\n",
    "    else:\n",
    "         best_model =hyperparameter_tuning(DecisionTreeRegressor())\n",
    "\n",
    "    ''' The above code compares the R2 score of each model to find the one with theb highest, making it the best model for hyperparameter tuning '''\n",
    "        \n",
    "    \n",
    "    return best_model\n",
    "\n",
    "Xtest = update_22[high_corr]\n",
    "Xtest = preprocessing(Xtest)\n",
    "Ytest = update_22['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5485fdae-a2b4-4d19-b62b-25cfdc9292ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Mean Absolute Error=2.3098790047977418\n",
      "    Mean Squared Error=8.882196688033224\n",
      "    Root Mean Squared Error=2.980301442477459\n",
      "    R2 score=0.7824134502104033\n",
      "    \n",
      "\n",
      "    Decision Tree regressor\n",
      "    Mean Absolute Error=1.2651999463646584\n",
      "    Mean Squared Error=4.724359315530526\n",
      "    Root Mean Squared Error=2.1735591355034547\n",
      "    R2 score=0.9056487999966436\n",
      "    \n",
      "\n",
      "    Random Forest Tree Regressor \n",
      "    Mean Absolute Error=1.0299038727377836\n",
      "    Mean Squared Error=2.4139844625343416\n",
      "    Root Mean Squared Error=1.5537002486111475\n",
      "    R2 score=0.9490714354760422\n",
      "    \n",
      "\n",
      "    XGBoost \n",
      "    Mean Absolute Error=1.1560693259182686\n",
      "    Mean Squared Error=2.571568776684252\n",
      "    Root Mean Squared Error=1.6036111675478728\n",
      "    R2 score=0.9454592893664154\n",
      "    \n",
      "LinearRegression CV mean R2 score: 0.820642989481388\n",
      "RandomForestRegressor CV mean R2 score: 0.950491285382207\n",
      "DecisionTreeRegressor CV mean R2 score: 0.9029280285104836\n",
      "XGBRegressor CV mean R2 score: 0.9472851179653841\n"
     ]
    }
   ],
   "source": [
    "optimised_model = select_model_training(Xtrain, Ytrain, X_train_test,Y_train_test) # runs the select_model_training function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c382760-3371-41c6-ba2e-29b5eceb5a65",
   "metadata": {},
   "source": [
    "## Model Perfomance Function\n",
    "\n",
    "The model_performance function contains the process of:\n",
    "\n",
    "Training a machine learning model (model.fit(X, Y)),\n",
    "\n",
    "Generating predictions for both the training and test sets (model.predict(X) and model.predict(Xt)),\n",
    "\n",
    "\n",
    "Computing evaluation metrics (MAE and RMSE) to assess the model's performance on both sets,\n",
    "\n",
    "Printing out these metrics in a clear and organized manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d0c4f-7962-4e68-bdb1-9d246c81d81e",
   "metadata": {},
   "source": [
    "\n",
    "## 4.Measure the model's performance and fine-tune it as a process of optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46935885-c092-475c-80a6-9b4f25afc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model, X, Y, Xt, Yt):\n",
    "    # Fit the model\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    Y_pred_train = model.predict(X) \n",
    "    Y_pred_test = model.predict(Xt)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_mae = mean_absolute_error(Y, Y_pred_train) # MAE for training set\n",
    "    train_rmse = np.sqrt(mean_squared_error(Yt,Y_pred_test))  # RMSE for training set\n",
    "    \n",
    "    # Calculate metrics for test set\n",
    "    test_mae = mean_absolute_error(Yt, Y_pred_test) #MAE for training set\n",
    "    test_rmse = np.sqrt(mean_squared_error(Yt,Y_pred_test))  # RMSE for test set\n",
    "\n",
    "    \n",
    "    print(f'Train MAE: {train_mae}')\n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print()\n",
    "    print(f'Test MAE: {test_mae}')\n",
    "    print(f'Test RMSE: {test_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afaf514e-0926-4fc6-8135-b542158f553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.5595931107503966\n",
      "Train RMSE: 1.5446114054698585\n",
      "\n",
      "Test MAE: 1.0320258925443428\n",
      "Test RMSE: 1.5446114054698585\n"
     ]
    }
   ],
   "source": [
    "model_performance(optimised_model,Xtrain, Ytrain, X_train_test,Y_train_test) #calls model performance function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c0e4b-a63e-42cb-907d-6ce9915c931c",
   "metadata": {},
   "source": [
    "### 5. Use the data from another season(players_22) which was not used during the training to test how good is the model. [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82351c80-ad63-45a3-ab74-c17f81042425",
   "metadata": {},
   "source": [
    "## 5.Test Model Function\n",
    "The test_model function is a straightforward  function used to evaluate a trained machine learning model on a separate test dataset (Xt, Yt)(i.e player_22 dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c857ec9-e554-45db-888c-c66c03908cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, Xt, Yt):\n",
    "    \n",
    "    new_pred = model.predict(Xt)\n",
    "    \n",
    "    test_data_mae = mean_absolute_error(Yt, new_pred)\n",
    "    test_data_rmse = np.sqrt(mean_squared_error(new_pred, Yt))\n",
    "    \n",
    "    print(f\"Test data MAE: {test_data_mae}\")\n",
    "    print(f\"Test data RMSE: {test_data_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88223102-010f-455a-87f1-08e970003a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data MAE: 0.763472377252185\n",
      "Test data RMSE: 1.2135496497480753\n"
     ]
    }
   ],
   "source": [
    "test_model(optimised_model, Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f24503-85e7-461e-ad6d-ae035dfe47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl # imports pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eda59c7-c18c-48e0-9f6b-f19f5f916d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a pickle file\n",
    "with open('Fifa_Regression_Model.pkl', 'wb') as file:\n",
    "    pkl.dump(optimised_model, file) #saves model as a pkl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063398b-791b-4bcf-ab5e-5af40f1a749a",
   "metadata": {},
   "source": [
    "## 6. Deploy the model on a simple web page using either (Heroku, Streamlite, or Flask) and upload a video that shows how the model performs on the web page/site. [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438340f-b9cc-437d-8b32-88ddca7d896c",
   "metadata": {},
   "source": [
    "1. To do this, I used the Streamlit library as it was the most straightforward and effective model for web app design using python.\n",
    "\n",
    "2. The source code for the development will be provided in the GIThub repository\n",
    "   \n",
    "3. Here is the link to the deployed application : https://emmanueladoteyacquayefifapredict.streamlit.app/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
